# Introduction

This repository contains code for exploring isomorphism between pre-trained language and vision embedding spaces. Implement transformer-based language models ([BERT](https://arxiv.org/abs/1810.04805), [GPT2](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf), [OPT](https://arxiv.org/abs/2205.01068)) to get words embeddings, and implemennt [ResNet](https://arxiv.org/abs/1512.03385) and [Segformer](https://arxiv.org/abs/2105.15203) to get images embeddings.

Before running the code, please download fasttext identification [model](https://fasttext.cc/docs/en/language-identification.html)

File path | Description
```
IPLVEs
â”œâ”€â”€ðŸ“‚ configs
â”‚   â”œâ”€â”€ bert_config.yaml
â”‚   â”œâ”€â”€ gpt2_config.yaml
â”‚   â”œâ”€â”€ opt_config.yaml
â”‚   â”œâ”€â”€ resnet_config.yaml
â”‚   â””â”€â”€ segformer_config.yaml
â”œâ”€â”€ðŸ“‚ data
â”‚   â””â”€â”€ wordlist.txt
â”œâ”€â”€ env.yaml
â”œâ”€â”€ __init__.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ main.py
â”œâ”€â”€ðŸ“‚ MUSE
â”‚   â””â”€â”€ ...
â”œâ”€â”€ðŸ“‚ pretrained
â”‚   â””â”€â”€ lid.176.bin
â”œâ”€â”€ README.md
â””â”€â”€ðŸ“‚ src
    â”œâ”€â”€ bert_word_emb.py
    â”œâ”€â”€ gpt2_word_emb.py
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ opt_word_emb.py
    â”œâ”€â”€ resnet_encode_categories.py
    â”œâ”€â”€ Segformer_encode.py
    â””â”€â”€ðŸ“‚ utils
        â”œâ”€â”€ build_dico_shuffle.py
        â”œâ”€â”€ build_dispersion_dictionaries.py
        â”œâ”€â”€ encode_util.py
        â”œâ”€â”€ get_dispersion.py
        â”œâ”€â”€ get_frequency.py
        â”œâ”€â”€ get_polysemy.py
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ io_util.py
        â””â”€â”€ sentences_downloader.py
```

## Get word embeddings

To get the embeddings of specific words in the wordlist, simply run:
```bash
python main.py --config ./configs/bert_config.yaml
```
## Get image embeddings
To get the embeddings of specific image class, simply run:
```bash
python main.py --config ./configs/segformer_config.yaml
```
## Align word and image embeddings
To learn a mapping between the source and the target space, simply run:
```bash
python MUSE/supervised.py  --src_lang image --tgt_lang word --emb_dim=512 --seed 42 --dico_train train_dict_path --dico_eval eval_dict_path --src_emb source_emb_path --tgt_emb target_emb_path --normalize_embeddings center --n_refinement 0;  
```